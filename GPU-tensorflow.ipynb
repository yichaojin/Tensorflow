{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'cifar10'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a0e9095172a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmax_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'cifar10'"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cifar10\n",
    "batch_size = 128\n",
    "max_steps = 1000\n",
    "num_gpus=1 # 具体gpu数量\n",
    "\n",
    "def tower_loss(scope):\n",
    "    images, labels = cifar10.distorted_inputs()\n",
    "    logits = cifar10.inference(images)\n",
    "    _ = cifar10.loss(logits, labels)\n",
    "    losses = tf.get_collection('losses', scope)\n",
    "    total_loss = tf.add_n(losses, name='total_loss')\n",
    "    return total_loss\n",
    "\n",
    "def average_gradients(tower_grads):\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "        grads = []\n",
    "        for g, _ in grad_and_vars:\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "            grads.append(expanded_g)\n",
    "\n",
    "        grad = tf.concat(grads, 0)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return  average_grads\n",
    "\n",
    "def train():\n",
    "    with tf.Graph().as_default(), tf.device('/cpu:0'):\n",
    "        global_step = tf.get_variable('global_step', [], initializer=tf.constant_initializer(0), trainable=False)\n",
    "        num_batches_per_epoch = cifar10.NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / batch_size\n",
    "        decay_steps = int(num_batches_per_epoch * cifar10.NUM_EPOCHS_PER_DECAY)\n",
    "        lr = tf.train.exponential_decay(cifar10.INITIAL_LEARNING_RATE,\n",
    "                                        global_step,\n",
    "                                        decay_steps,\n",
    "                                        cifar10.LEARNING_RATE_DECAY_FACTOR,\n",
    "                                        staircase=True)\n",
    "        opt = tf.train.GradientDescentOptimizer(lr)\n",
    "\n",
    "        tower_grads = []\n",
    "        for i in range(num_gpus):\n",
    "            with tf.device('/gpu:%d' % i):\n",
    "                with tf.name_scope('%s_%d' % (cifar10.TOWER_NAME, i)) as scope:\n",
    "                    loss = tower_loss(scope)\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "                    grads = opt.compute_gradients(loss)\n",
    "                    tower_grads.append(grads)\n",
    "        grads = average_gradients(tower_grads)\n",
    "        apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "        saver = tf.train.Saver(tf.all_variables())\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "        sess.run(init)\n",
    "        tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            start_time = time.time()\n",
    "            _, loss_value = sess.run([apply_gradient_op, loss])\n",
    "            duration = time.time() - start_time\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                num_examples_per_step = batch_size * num_gpus\n",
    "                examples_per_sec = num_examples_per_step / duration\n",
    "                sec_per_batch = duration / num_gpus\n",
    "\n",
    "                format_str = ('step %d, loss = %.2f (%.1f examples/sec; %.3f ' 'sec/batch)')\n",
    "                print(format_str % (step, loss_value, examples_per_sec, sec_per_batch))\n",
    "\n",
    "            if step % 1000 == 0 or (step + 1) == max_steps:\n",
    "                saver.save(sess, 'cifar10_train/model.ckpt', global_step=step) # 需要在当前py文件下存在cifar10_train目录\n",
    "\n",
    "cifar10.maybe_download_and_extract()\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.distributions import Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'beta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-7fb6bd788154>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3.0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m11.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGamma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mshapel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mshape2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'beta'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "alpha = tf.constant([3.0] * 5)\n",
    "beta = tf.constant (11.0)\n",
    "gamma = Gamma(alpha=alpha,beta=beta)\n",
    "shapel = gamma.batch_shape().eval()\n",
    "shape2 = gamma.get_batch_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
